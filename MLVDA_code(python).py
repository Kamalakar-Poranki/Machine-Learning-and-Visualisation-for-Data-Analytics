# -*- coding: utf-8 -*-
"""MLVDA_CODE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M6b-Jr1tQuYE6XIUCz2m5zeKkxhwCbL0
"""

pip install imblearn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix, precision_recall_curve
from sklearn.preprocessing import MinMaxScaler

# Load dataset
synthetic_data = pd.read_csv('/content/PS_20174392719_1491204439457_log.csv')

# Check structure and basic info
print(synthetic_data.head())

# Check for missing values
print(synthetic_data.isnull().sum())

# Check data types
print(synthetic_data.dtypes)

# Mean, standard deviation for all the numerical variable
synthetic_data.describe()

# Checking class imbalance
print("\nClass distribution before balancing:")
print(synthetic_data['isFraud'].value_counts())

# Encode categorical features
le = LabelEncoder()
synthetic_data['type'] = le.fit_transform(synthetic_data['type'])

# Splitting features and target
X = synthetic_data.drop(['isFraud', 'nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1)
y = synthetic_data['isFraud']

# Feature scaling
scaler = MinMaxScaler()
X[['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']] = scaler.fit_transform(
    X[['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]
)

# Balancing the classes using the SMOTE technique
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Review the class distribution before and after SMOTE
print("\nClass distribution after SMOTE:")
print(pd.Series(y_res).value_counts())

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)

# Train Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predictions
y_pred = rf_model.predict(X_test)
y_pred_prob = rf_model.predict_proba(X_test)[:, 1]

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, marker='.', label='Random Forest')
plt.title("Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.legend()
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, marker='.', label='Random Forest (AUC = {:.3f})'.format(roc_auc_score(y_test, y_pred_prob)))
plt.title("ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

# Classification Report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Identify rows from the original test set that corresponds to the predictions
X_test_original = X_test.copy()
X_test_original['Actual'] = y_test
X_test_original['Predicted'] = y_pred
X_test_original['Prediction_Probability'] = y_pred_prob

# Fitting into the shape that Tableau expects by including the necessary columns back
X_test_original['type'] = le.inverse_transform(X_test_original['type'])  # Decode 'type' column
X_test_original['TransactionID'] = X_test_original.index  # A new column TransactionID has been included to facilitate identification of transactions.

# The final results are available to download in the form of the CSV file.
X_test_original.to_csv('Data Set.csv', index=False)
print("\nFinal dataset saved to 'Data Set.csv'")

# Show samples of the final dataset
print("\nPreview of the final dataset:")
print(X_test_original.head())
print("\nFinal dataset shape:", X_test_original.shape)

from google.colab import files
files.download('/content/Data Set.csv')